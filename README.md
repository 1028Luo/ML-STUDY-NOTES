# Study-Notes

Content included:

1. Supervised Learning:
   
     1.1 Classification:
   
       1.1.1 Logistic regression
   
       1.1.2 Random forest
   
   KNN (K Nearest Neighbor)
   
   SVM
   
   Neural Networks
   
   Decision Trees
   
     1.2 Regression(like classification in continuous space):
       1.2.1 Linear Regression
       Random Forest Regression
       Decision Trees Regression
   SVM, Neural Networks

Ensemble methods:
Ensemble methods generate prediction from a group of models
a. bagging ensemble methods: random forest, trains multiple trees in parallel and the prediction is their average(continous) or most-voted(discrete)
b. boosting ensemble methods: XG Boost, train F0 and get error between F0 and Y
train a new model h1 so that error(F0 + h1 = F1, Y) is lower
iterate this step to reduce error(F1, Y) by training error(F1 + h2 = F2, Y)

Time Series Forcasting
   
2. Unsupervised Learning	
  Clustering:
  
  Anomaly Detection,
  K Clustering
Dimensionality Reduction	K-Means, PCA, DBSCAN

3. Reinforcement Learning:
  Game AI, Robotics	Q-Learning, PPO, DQN

4. Generative Models:

   Vanilla transformer
   
   LLAMA 2 transformer
   
   MoE
   
   fast attention
  AI-generated text/images	GANs, VAEs

6. Data processing

9. other
    
Recommendation Systems:
  Netflix, Amazon Suggestions	Collaborative Filtering, Deep Learning
NLP & Vision:
  Chatbots, Object Detection	BERT, GPT, CNNs, Vision Transformers


TO DO:
1. Look into Triton and CUDA

2. Some more ML learning and summarize

3. Leetcode everyday
