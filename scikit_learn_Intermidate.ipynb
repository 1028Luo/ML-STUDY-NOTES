{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyORLVYf0oTeEerm4UOgaR55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1028Luo/ML-STUDY-NOTES/blob/main/scikit_learn_Intermidate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlbFc_kMwlWA"
      },
      "outputs": [],
      "source": [
        "# code implementation to the kaggle tutorial:\n",
        "# https://www.kaggle.com/learn/intermediate-machine-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling missing values"
      ],
      "metadata": {
        "id": "ElsvYVK1FBVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install and import\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# import data\n",
        "path = kagglehub.dataset_download(\"dansbecker/melbourne-housing-snapshot\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "melb_data = pd.read_csv(f\"{path}/melb_data.csv\")\n",
        "melb_data.head()\n",
        "\n",
        "# spilt data\n",
        "y = melb_data.Price\n",
        "melb_features = ['Rooms', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt'] # cannot contain string\n",
        "x = melb_data[melb_features]\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(x, y, random_state = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihrsn_Au1Z2y",
        "outputId": "2b462f58-8d77-4838-86e5-53f4e9679434"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/dansbecker/melbourne-housing-snapshot/versions/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values\n",
        "# There are many ways data can end up with missing values. For example,\n",
        "#   A 2 bedroom house won't include a value for the size of a third bedroom.\n",
        "#   A survey respondent may choose not to share his income.\n",
        "# Options are:\n",
        "#   1. drop the whole column\n",
        "#   2. Imputation: add a number, like the mean of the whole column\n",
        "#   3. Better imputation: add another row indicating if imputation is used for a row with True/False\n",
        "\n",
        "# define a score function\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def score_dataset(train_x, train_y, val_x, val_y):\n",
        "  model = RandomForestRegressor(random_state=1)\n",
        "  model.fit(train_x, train_y)\n",
        "  result = model.predict(val_x)\n",
        "  print(mean_absolute_error(result, val_y))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yZDof_AQ0YoI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### drop column #####\n",
        "\n",
        "col_missing = [col for col in train_x if train_x[col].isnull().any()]\n",
        "print(col_missing)\n",
        "print(train_x.shape)\n",
        "print(val_x.shape)\n",
        "\n",
        "reduced_train_x = train_x.drop(col_missing, axis = 1)\n",
        "reduced_val_x = val_x.drop(col_missing, axis = 1)\n",
        "\n",
        "score_dataset(reduced_train_x, train_y, reduced_val_x, val_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kvlQZhhD7ZQ",
        "outputId": "138521e6-a983-4c31-9963-0e262e35b913"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Car', 'BuildingArea', 'YearBuilt']\n",
            "(10185, 5)\n",
            "(3395, 5)\n",
            "415009.8166920805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### imputation #####\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_train_x = pd.DataFrame(my_imputer.fit_transform(train_x))\n",
        "imputed_val_x = pd.DataFrame(my_imputer.fit_transform(val_x))\n",
        "\n",
        "# Imputation removed column names; put them back\n",
        "imputed_train_x.columns = train_x.columns\n",
        "imputed_val_x.columns = val_x.columns\n",
        "\n",
        "print(score_dataset(imputed_train_x, train_y, imputed_val_x, val_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llzqTK_XD5Mj",
        "outputId": "18ef802a-ec15-4cd9-de5e-63a04b5015a3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "329838.8176470143\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_9g5lPsEE66j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Categorical variables"
      ],
      "metadata": {
        "id": "NhEe4pNeFI4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There can be categorical variables in the dataset,\n",
        "# like: never, rarely, often, everyday\n",
        "# Options:\n",
        "#   1. drop\n",
        "#   2. encoding: 0 for never, 1 for rarely, 2 for often\n",
        "#   3. one-hot encoding: 000 for never, 001 for rarely, 010 for often"
      ],
      "metadata": {
        "id": "z2Jc89jaFM0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### drop #####\n",
        "\n",
        "# Get list of categorical variables\n",
        "s = (X_train.dtypes == 'object')\n",
        "object_cols = list(s[s].index)\n",
        "\n",
        "print(\"Categorical variables:\")\n",
        "print(object_cols)\n",
        "\n",
        "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
        "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
        "\n",
        "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
        "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))\n"
      ],
      "metadata": {
        "id": "JI5gRY_4OAxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### encoding #####\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# Make copy to avoid changing original data\n",
        "label_X_train = X_train.copy()\n",
        "label_X_valid = X_valid.copy()\n",
        "\n",
        "# Apply ordinal encoder to each column with categorical data\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
        "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
        "\n",
        "print(\"MAE from Approach 2 (Ordinal Encoding):\")\n",
        "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
      ],
      "metadata": {
        "id": "Y7I-j3C3ORz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipelines"
      ],
      "metadata": {
        "id": "F2P1NcSOSTep"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "39Dq8GVBSWVv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}